{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc510ae",
   "metadata": {},
   "source": [
    "# Milestone 3 - Client side Encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267068ea",
   "metadata": {},
   "source": [
    "This notebook demonstrates the **client-side pipeline** for the ZK-LLMS project:\n",
    "\n",
    "- Generate **synthetic embeddings** shaped like TinyLlama outputs (e.g. `(seq_len=10, dim=2048)`).\n",
    "- Create a **CKKS context** with TenSEAL (same parameters as the client).\n",
    "- **Encrypt** embeddings and build the same JSON **payload** the client sends.\n",
    "- **Simulate** the server-side `/api/infer` handler:\n",
    "  - Deserialize and decrypt one encrypted vector.\n",
    "  - Generate a dummy encrypted result.\n",
    "- **Decrypt** the server's encrypted response on the client.\n",
    "- Measure **latency** for each step.\n",
    "\n",
    "This notebook uses **no external model downloads** and **no network calls**, so it’s safe for public execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b6fa4",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7b783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab or a fresh environment, you may need:\n",
    "# !pip install tenseal numpy pyyaml\n",
    "\n",
    "import time\n",
    "import base64\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021501b",
   "metadata": {},
   "source": [
    "### Configuration & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f33e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CKKS parameters — aligned with client_config.yaml / server_config.yaml\n",
    "ckks_config = {\n",
    "    \"poly_modulus_degree\": 8192,\n",
    "    \"coeff_mod_bit_sizes\": [60, 40, 40, 60],\n",
    "    \"global_scale\": 2**40,\n",
    "}\n",
    "\n",
    "# Synthetic embedding shape (like TinyLlama last hidden state)\n",
    "SEQ_LEN = 10       # number of tokens\n",
    "HIDDEN_DIM = 2048  # embedding dimension\n",
    "\n",
    "\n",
    "def create_ckks_context(config: Dict[str, Any]) -> ts.Context:\n",
    "    \"\"\"Create a TenSEAL CKKS context using the given configuration.\"\"\"\n",
    "    context = ts.context(\n",
    "        ts.SCHEME_TYPE.CKKS,\n",
    "        poly_modulus_degree=config[\"poly_modulus_degree\"],\n",
    "        coeff_mod_bit_sizes=config[\"coeff_mod_bit_sizes\"],\n",
    "    )\n",
    "    context.global_scale = config[\"global_scale\"]\n",
    "    context.generate_galois_keys()\n",
    "    # NOTE: we keep the secret key for the demo (client + server in same notebook)\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c5eb9",
   "metadata": {},
   "source": [
    "### Generate Synthetic Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20d0cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic embeddings shape: (10, 2048)\n",
      "Generation time: 0.94 ms\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "start = time.perf_counter()\n",
    "embeddings = np.random.normal(loc=0.0, scale=0.02, size=(SEQ_LEN, HIDDEN_DIM))\n",
    "elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "print(f\"Synthetic embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Generation time: {elapsed_ms:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29ca5f",
   "metadata": {},
   "source": [
    "### Create CKKS Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99059363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKKS context created.\n",
      "poly_modulus_degree: 8192\n",
      "coeff_mod_bit_sizes: [60, 40, 40, 60]\n",
      "Context creation time: 112.87 ms\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "context = create_ckks_context(ckks_config)\n",
    "elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "print(\"CKKS context created.\")\n",
    "print(f\"poly_modulus_degree: {ckks_config['poly_modulus_degree']}\")\n",
    "print(f\"coeff_mod_bit_sizes: {ckks_config['coeff_mod_bit_sizes']}\")\n",
    "print(f\"Context creation time: {elapsed_ms:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223eaaf9",
   "metadata": {},
   "source": [
    "### Encrypt Embeddings & Serialize\n",
    "Here we mimic your encrypt_embeddings() + serialize_encrypted_vectors() logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab946ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted 10 token embeddings.\n",
      "Encryption + serialization time: 46.04 ms\n",
      "Example serialized ciphertext length: 445884 characters\n"
     ]
    }
   ],
   "source": [
    "def encrypt_embeddings(emb: np.ndarray, context: ts.Context) -> List[ts.CKKSVector]:\n",
    "    \"\"\"\n",
    "    Encrypt each token embedding row as a separate CKKS vector.\n",
    "    emb shape: (seq_len, hidden_dim)\n",
    "    \"\"\"\n",
    "    encrypted = []\n",
    "    for i in range(emb.shape[0]):\n",
    "        vec = ts.ckks_vector(context, emb[i].tolist())\n",
    "        encrypted.append(vec)\n",
    "    return encrypted\n",
    "\n",
    "\n",
    "def serialize_encrypted_vectors(vectors: List[ts.CKKSVector]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Serialize CKKS vectors and encode them as base64 strings.\n",
    "    \"\"\"\n",
    "    serialized = []\n",
    "    for v in vectors:\n",
    "        raw = v.serialize()\n",
    "        b64 = base64.b64encode(raw).decode(\"utf-8\")\n",
    "        serialized.append(b64)\n",
    "    return serialized\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "encrypted_vectors = encrypt_embeddings(embeddings, context)\n",
    "serialized_vectors = serialize_encrypted_vectors(encrypted_vectors)\n",
    "elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "print(f\"Encrypted {len(encrypted_vectors)} token embeddings.\")\n",
    "print(f\"Encryption + serialization time: {elapsed_ms:.2f} ms\")\n",
    "print(f\"Example serialized ciphertext length: {len(serialized_vectors[0])} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a724545",
   "metadata": {},
   "source": [
    "### Build Client Payload\n",
    "This mimics your build_payload() function and attaches metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b78869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload built with CID: c14942de-3d41-48f7-a5f1-2d7b98db2317\n",
      "Payload size: 4457845 bytes\n",
      "Build time: 11.07 ms\n"
     ]
    }
   ],
   "source": [
    "def build_payload(serialized_vecs: List[str],\n",
    "                  emb_shape: tuple,\n",
    "                  ckks_cfg: Dict[str, Any],\n",
    "                  cid: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build JSON-ready payload, similar to the client implementation.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"encrypted_embeddings\": serialized_vecs,\n",
    "        \"metadata\": {\n",
    "            \"cid\": cid,\n",
    "            \"embedding_shape\": list(emb_shape),\n",
    "            \"ckks\": {\n",
    "                \"poly_modulus_degree\": ckks_cfg[\"poly_modulus_degree\"],\n",
    "                \"coeff_mod_bit_sizes\": ckks_cfg[\"coeff_mod_bit_sizes\"],\n",
    "                \"global_scale\": ckks_cfg[\"global_scale\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "\n",
    "import uuid, json\n",
    "\n",
    "cid = str(uuid.uuid4())\n",
    "start = time.perf_counter()\n",
    "payload = build_payload(serialized_vectors, embeddings.shape, ckks_config, cid)\n",
    "payload_bytes = len(json.dumps(payload).encode(\"utf-8\"))\n",
    "elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "print(f\"Payload built with CID: {cid}\")\n",
    "print(f\"Payload size: {payload_bytes} bytes\")\n",
    "print(f\"Build time: {elapsed_ms:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbb98e",
   "metadata": {},
   "source": [
    "### Mock Server /api/infer Logic\n",
    "This simulates your FastAPI infer() handler (but locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6dc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_server_infer(payload: Dict[str, Any], context: ts.Context) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simulated server-side handler for /api/infer.\n",
    "\n",
    "    - Deserializes the first encrypted embedding.\n",
    "    - Decrypts it (for debugging / testing).\n",
    "    - Prints diagnostics.\n",
    "    - Returns a dummy encrypted result as the server would.\n",
    "    \"\"\"\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    encrypted_embeddings = payload.get(\"encrypted_embeddings\", [])\n",
    "    metadata = payload.get(\"metadata\", {})\n",
    "\n",
    "    # Deserialize & decrypt just the first embedding for demonstration\n",
    "    if not encrypted_embeddings:\n",
    "        raise ValueError(\"No encrypted embeddings in payload\")\n",
    "\n",
    "    first_b64 = encrypted_embeddings[0]\n",
    "    enc_bytes = base64.b64decode(first_b64)\n",
    "    enc_vec = ts.ckks_vector_from(context, enc_bytes)\n",
    "    decrypted = enc_vec.decrypt()\n",
    "\n",
    "    print(f\"[SERVER] Received {len(encrypted_embeddings)} encrypted embeddings.\")\n",
    "    print(f\"[SERVER] Example decrypted slice (first 5 values): {decrypted[:5]}\")\n",
    "\n",
    "    # Dummy encrypted result (like your server)\n",
    "    dummy_result = [0.1, 0.2, 0.3]\n",
    "    enc_result = ts.ckks_vector(context, dummy_result)\n",
    "    result_b64 = base64.b64encode(enc_result.serialize()).decode(\"utf-8\")\n",
    "\n",
    "    elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "    print(f\"[SERVER] Inference (mock) time: {elapsed_ms:.2f} ms\")\n",
    "\n",
    "    return {\"encrypted_result\": result_b64}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa14386",
   "metadata": {},
   "source": [
    "### Simulate Client → Server → Client Roundtrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c0459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Received 10 encrypted embeddings.\n",
      "[SERVER] Example decrypted slice (first 5 values): [0.009934283129673415, -0.0027652855974043228, 0.01295377051659382, 0.030460597502334052, -0.004683065634977897]\n",
      "[SERVER] Inference (mock) time: 9.57 ms\n",
      "\n",
      "[CLIENT] Decrypted server result: [0.10000000046121574, 0.19999999664931548, 0.3000000005207714]\n",
      "[CLIENT] Mock server time: 9.76 ms\n",
      "[CLIENT] End-to-end (client→server→client) time: 12.45 ms\n"
     ]
    }
   ],
   "source": [
    "# Simulate the \"HTTP POST\" by calling mock_server_infer directly\n",
    "start_total = time.perf_counter()\n",
    "\n",
    "start = time.perf_counter()\n",
    "server_response = mock_server_infer(payload, context)\n",
    "server_time_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "# Client decrypts server's encrypted_result\n",
    "enc_result_b64 = server_response[\"encrypted_result\"]\n",
    "enc_bytes = base64.b64decode(enc_result_b64)\n",
    "enc_vec = ts.ckks_vector_from(context, enc_bytes)\n",
    "decrypted_result = enc_vec.decrypt()\n",
    "roundtrip_time_ms = (time.perf_counter() - start_total) * 1000\n",
    "\n",
    "print(f\"\\n[CLIENT] Decrypted server result: {decrypted_result}\")\n",
    "print(f\"[CLIENT] Mock server time: {server_time_ms:.2f} ms\")\n",
    "print(f\"[CLIENT] End-to-end (client→server→client) time: {roundtrip_time_ms:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ad09f",
   "metadata": {},
   "source": [
    "### Summary & Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360caa2",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrated:\n",
    "\n",
    "- Generating **synthetic embeddings** shaped like TinyLlama outputs (`(10, 2048)`).\n",
    "- Creating a **CKKS context** with the same parameters used by the client and server.\n",
    "- Encrypting each token embedding row as a **CKKS vector** and serializing it to base64.\n",
    "- Building a **JSON payload** with:\n",
    "  - `encrypted_embeddings`: list of ciphertexts\n",
    "  - `metadata`: `cid`, embedding shape, CKKS parameters\n",
    "- Simulating the **server-side `/api/infer`**:\n",
    "  - Deserializing and decrypting an embedding.\n",
    "  - Returning a dummy encrypted result.\n",
    "- Performing **client-side decryption** of the server's response.\n",
    "- Measuring **latency** for encryption, payload building, and mock inference.\n",
    "\n",
    "This notebook mirrors the **client-side logic** from the Phase 2 implementation\n",
    "but removes external dependencies (TinyLlama model, network calls),\n",
    "making it suitable as a **public, reproducible milestone deliverable**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "split-inference-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
