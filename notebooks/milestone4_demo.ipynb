{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 4: Privacy-Preserving Split Inference Demo\n",
    "\n",
    "This notebook demonstrates the core building blocks of ZK-LLM-Turbo's split inference:\n",
    "1. CKKS public context (prove server can't decrypt)\n",
    "2. Homomorphic matrix multiplication\n",
    "3. Non-linear operations (RMSNorm, SiLU) comparison vs PyTorch\n",
    "4. Full 1-layer encrypted inference timing breakdown\n",
    "5. Accuracy comparison: encrypted vs plaintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CKKS Public Context Demo\n",
    "\n",
    "The client creates a CKKS context with a secret key, then serializes it *without* the secret key.\n",
    "The server receives the public context and can perform computations but **cannot decrypt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from client.encryption.ckks_context import create_ckks_context, serialize_public_context\n\n# Client creates full context (has secret key)\nclient_ctx = create_ckks_context(config_path=\"../client/config/client_config.yaml\")\n\n# Serialize public-only context\npublic_bytes = serialize_public_context(client_ctx)\nprint(f\"Public context size: {len(public_bytes) / 1024:.1f} KB\")\n\n# Server loads public context\nserver_ctx = ts.context_from(public_bytes)\n\n# Client encrypts\nsecret_data = [3.14, 2.71, 1.41, 1.73]\nenc_vec = ts.ckks_vector(client_ctx, secret_data)\n\n# Server receives ciphertext\nserver_vec = ts.ckks_vector_from(server_ctx, enc_vec.serialize())\n\n# Server CANNOT decrypt\ntry:\n    server_vec.decrypt()\n    print(\"ERROR: Server decrypted! This should not happen.\")\nexcept Exception as e:\n    print(f\"Server cannot decrypt (expected): {type(e).__name__}\")\n\n# Client CAN decrypt\nclient_result = ts.ckks_vector_from(client_ctx, enc_vec.serialize())\nprint(f\"Client decrypts: {client_result.decrypt()[:4]}\")\nprint(f\"Original data:   {secret_data}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HE Matrix Multiplication Demo\n",
    "\n",
    "Server computes `Enc(x) @ W` homomorphically without seeing `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a small projection: 64-dim input → 32-dim output\n",
    "dim_in, dim_out = 64, 32\n",
    "x = np.random.randn(dim_in).astype(np.float32) * 0.1\n",
    "W = np.random.randn(dim_in, dim_out).astype(np.float32) * 0.1\n",
    "\n",
    "# Plaintext result\n",
    "expected = x @ W\n",
    "\n",
    "# Client encrypts x\n",
    "enc_x = ts.ckks_vector(client_ctx, x.tolist())\n",
    "\n",
    "# Server computes enc_x @ W\n",
    "server_enc = ts.ckks_vector_from(server_ctx, enc_x.serialize())\n",
    "t0 = time.perf_counter()\n",
    "enc_result = server_enc.mm(W.tolist())\n",
    "he_time = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "# Client decrypts\n",
    "actual = np.array(ts.ckks_vector_from(client_ctx, enc_result.serialize()).decrypt()[:dim_out])\n",
    "\n",
    "error = np.abs(actual - expected)\n",
    "print(f\"HE matmul ({dim_in}→{dim_out}): {he_time:.1f} ms\")\n",
    "print(f\"Max error: {error.max():.6f}\")\n",
    "print(f\"Mean error: {error.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-scale: 2048-dim input → 256-dim output (like K/V projection)\n",
    "dim_in, dim_out = 2048, 256\n",
    "x = np.random.randn(dim_in).astype(np.float32) * 0.01\n",
    "W = np.random.randn(dim_in, dim_out).astype(np.float32) * 0.01\n",
    "\n",
    "expected = x @ W\n",
    "enc_x = ts.ckks_vector(client_ctx, x.tolist())\n",
    "server_enc = ts.ckks_vector_from(server_ctx, enc_x.serialize())\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "enc_result = server_enc.mm(W.tolist())\n",
    "he_time = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "actual = np.array(ts.ckks_vector_from(client_ctx, enc_result.serialize()).decrypt()[:dim_out])\n",
    "error = np.abs(actual - expected)\n",
    "\n",
    "print(f\"HE matmul ({dim_in}→{dim_out}): {he_time:.1f} ms\")\n",
    "print(f\"Max error: {error.max():.6f}\")\n",
    "print(f\"Mean error: {error.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Non-Linear Operations: Our NumPy vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.inference.nonlinear_ops import rms_norm, silu, softmax\n",
    "\n",
    "# RMSNorm comparison\n",
    "x_np = np.random.randn(2048).astype(np.float32)\n",
    "w_np = np.random.randn(2048).astype(np.float32)\n",
    "\n",
    "our_norm = rms_norm(x_np, w_np, eps=1e-5)\n",
    "\n",
    "x_t = torch.tensor(x_np)\n",
    "w_t = torch.tensor(w_np)\n",
    "variance = x_t.pow(2).mean(-1, keepdim=True)\n",
    "pt_norm = ((x_t * torch.rsqrt(variance + 1e-5)) * w_t).numpy()\n",
    "\n",
    "print(f\"RMSNorm max diff: {np.abs(our_norm - pt_norm).max():.2e}\")\n",
    "\n",
    "# SiLU comparison\n",
    "x_np = np.random.randn(1000).astype(np.float32)\n",
    "our_silu = silu(x_np)\n",
    "pt_silu = torch.nn.functional.silu(torch.tensor(x_np)).numpy()\n",
    "print(f\"SiLU max diff: {np.abs(our_silu - pt_silu).max():.2e}\")\n",
    "\n",
    "# Softmax comparison\n",
    "x_np = np.random.randn(32, 32).astype(np.float32)\n",
    "our_sm = softmax(x_np)\n",
    "pt_sm = torch.nn.functional.softmax(torch.tensor(x_np), dim=-1).numpy()\n",
    "print(f\"Softmax max diff: {np.abs(our_sm - pt_sm).max():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Timing Breakdown: Encrypted Operations\n",
    "\n",
    "Measure the cost of each component in a single round-trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 2048\n",
    "kv_dim = 256\n",
    "ffn_dim = 5632\n",
    "\n",
    "x = np.random.randn(hidden_dim).astype(np.float32) * 0.01\n",
    "W_q = np.random.randn(hidden_dim, hidden_dim).astype(np.float32) * 0.005\n",
    "W_k = np.random.randn(hidden_dim, kv_dim).astype(np.float32) * 0.005\n",
    "\n",
    "# Encryption time\n",
    "t0 = time.perf_counter()\n",
    "enc_x = ts.ckks_vector(client_ctx, x.tolist())\n",
    "encrypt_ms = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "# Serialize time\n",
    "t0 = time.perf_counter()\n",
    "enc_bytes = enc_x.serialize()\n",
    "serialize_ms = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "# Matmul Q (2048→2048)\n",
    "t0 = time.perf_counter()\n",
    "enc_q = enc_x.mm(W_q.tolist())\n",
    "mm_q_ms = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "# Matmul K (2048→256)\n",
    "enc_x2 = ts.ckks_vector(client_ctx, x.tolist())  # fresh for fair comparison\n",
    "t0 = time.perf_counter()\n",
    "enc_k = enc_x2.mm(W_k.tolist())\n",
    "mm_k_ms = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "# Decrypt time\n",
    "t0 = time.perf_counter()\n",
    "dec = enc_q.decrypt()\n",
    "decrypt_ms = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "print(\"=== Timing Breakdown (single token) ===\")\n",
    "print(f\"Encrypt (2048-dim):     {encrypt_ms:8.1f} ms\")\n",
    "print(f\"Serialize:              {serialize_ms:8.1f} ms\")\n",
    "print(f\"HE matmul 2048→2048:    {mm_q_ms:8.1f} ms\")\n",
    "print(f\"HE matmul 2048→256:     {mm_k_ms:8.1f} ms\")\n",
    "print(f\"Decrypt (2048-dim):     {decrypt_ms:8.1f} ms\")\n",
    "print(f\"Ciphertext size:        {len(enc_bytes) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Accuracy: Encrypted vs Plaintext Layer Output\n",
    "\n",
    "Compare a full encrypted matmul chain (simulating Q projection) against plaintext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate: RMSNorm → encrypt → Q projection → decrypt\n",
    "hidden_dim = 2048\n",
    "x = np.random.randn(hidden_dim).astype(np.float32) * 0.01\n",
    "norm_w = np.ones(hidden_dim, dtype=np.float32)\n",
    "W_q = np.random.randn(hidden_dim, hidden_dim).astype(np.float32) * 0.005\n",
    "\n",
    "# Plaintext pipeline\n",
    "x_normed = rms_norm(x, norm_w, 1e-5)\n",
    "q_plain = x_normed @ W_q\n",
    "\n",
    "# Encrypted pipeline\n",
    "enc_normed = ts.ckks_vector(client_ctx, x_normed.tolist())\n",
    "enc_q = enc_normed.mm(W_q.tolist())\n",
    "q_enc = np.array(enc_q.decrypt()[:hidden_dim], dtype=np.float32)\n",
    "\n",
    "error = np.abs(q_plain - q_enc)\n",
    "print(f\"Encrypted vs Plaintext Q-projection ({hidden_dim}→{hidden_dim}):\")\n",
    "print(f\"  Max error:  {error.max():.6f}\")\n",
    "print(f\"  Mean error: {error.mean():.6f}\")\n",
    "print(f\"  Relative error: {(error / (np.abs(q_plain) + 1e-10)).mean():.4%}\")\n",
    "\n",
    "# Cosine similarity\n",
    "cos_sim = np.dot(q_plain, q_enc) / (np.linalg.norm(q_plain) * np.linalg.norm(q_enc))\n",
    "print(f\"  Cosine similarity: {cos_sim:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Privacy**: Server has public context only → cannot decrypt any ciphertexts\n",
    "- **Correctness**: HE matmul matches plaintext within CKKS tolerance (~0.01 for small dims)\n",
    "- **Non-linear ops**: Our NumPy implementations match PyTorch within float32 epsilon\n",
    "- **Performance**: Single HE matmul at 2048 dims takes ~X ms per token\n",
    "- **Architecture**: 4 round-trips per layer, configurable number of encrypted layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}